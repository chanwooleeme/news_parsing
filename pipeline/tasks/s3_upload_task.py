from logger import get_logger
from utils.file import list_files, join_path, list_directories
import os
import boto3
from botocore.exceptions import ClientError

logger = get_logger(__name__)

def find_html_files_recursive(dir_path):
    """ì£¼ì–´ì§„ ë””ë ‰í† ë¦¬ì™€ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ HTML íŒŒì¼ ì°¾ê¸°"""
    all_html_files = []
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ HTML íŒŒì¼
    try:
        current_html_files = [join_path(dir_path, f) for f in list_files(dir_path, extension=".html")]
        all_html_files.extend(current_html_files)
    except Exception as e:
        logger.error(f"í˜„ì¬ ë””ë ‰í† ë¦¬ {dir_path} ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì— ëŒ€í•´ ì¬ê·€ì ìœ¼ë¡œ íŒŒì¼ ì°¾ê¸°
    try:
        subdirs = list_directories(dir_path)
        for subdir in subdirs:
            subdir_path = join_path(dir_path, subdir)
            subdirectory_files = find_html_files_recursive(subdir_path)
            all_html_files.extend(subdirectory_files)
    except Exception as e:
        logger.error(f"í•˜ìœ„ ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    return all_html_files

def upload_to_s3(file_path: str, bucket_name: str, object_key: str, 
                content_type: str = 'text/markdown'):
    """
    ë‹¨ì¼ íŒŒì¼ì„ S3ì— ì—…ë¡œë“œ (ACL ì—†ì´)
    """
    logger.info(f"ğŸ”„ S3 ì—…ë¡œë“œ ì‹œì‘: {file_path} -> s3://{bucket_name}/{object_key}")
    
    try:
        if not os.path.exists(file_path):
            logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return False

        s3_client = boto3.client("s3", region_name="ap-northeast-2")

        extra_args = {
            'ContentType': content_type,
            'CacheControl': 'no-cache, max-age=0'
        }
        
        s3_client.upload_file(
            Filename=file_path,
            Bucket=bucket_name,
            Key=object_key,
            ExtraArgs=extra_args
        )
        
        logger.info(f"âœ… S3 ì—…ë¡œë“œ ì™„ë£Œ: s3://{bucket_name}/{object_key}")
        return True
        
    except ClientError as e:
        logger.error(f"âŒ S3 ì—…ë¡œë“œ ì‹¤íŒ¨ (ClientError): {str(e)}")
        return False
    except Exception as e:
        logger.error(f"âŒ S3 ì—…ë¡œë“œ ì‹¤íŒ¨ (Exception): {str(e)}")
        return False


def s3_upload_task(html_dir: str):
    try:
        logger.info(f"Starting S3 upload task for {html_dir}")
        s3_client = boto3.client("s3", region_name="ap-northeast-2")
        html_dir_with_separator = html_dir if html_dir.endswith(os.sep) else html_dir + os.sep
        
        # ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  HTML íŒŒì¼ ì°¾ê¸°
        html_files = find_html_files_recursive(html_dir)
        logger.info(f"Found {len(html_files)} HTML files to upload")
        
        if not html_files:
            logger.warning(f"No HTML files found in {html_dir}")
            return
            
        for html_path in html_files:
            try:
                # html_dir ê²½ë¡œë¥¼ ì œì™¸í•œ ìƒëŒ€ ê²½ë¡œë¥¼ S3 í‚¤ë¡œ ì‚¬ìš©
                s3_key = html_path.replace(html_dir_with_separator, "")
                logger.info(f"Uploading {html_path} to S3 bucket with key {s3_key}")
                s3_client.upload_file(html_path, "article-crawl-html-storage", s3_key)
                logger.info(f"Successfully uploaded {html_path} to s3 with key {s3_key}")
            except ClientError as e:
                logger.error(f"Failed to upload {html_path}: {str(e)}")
                continue
            except FileNotFoundError:
                logger.error(f"File not found: {html_path}")
                continue
                
        logger.info(f"Uploaded all HTML files in {html_dir} to s3")
    except Exception as e:
        logger.error(f"Error in S3 upload task: {str(e)}")
        raise

