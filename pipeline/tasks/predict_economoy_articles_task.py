from typing import List, Dict
from logging import getLogger
from utils.file import list_directories, list_files, join_path, read_json_file
import asyncio
import aiohttp

logger = getLogger(__name__)
MAX_BATCH_SIZE = 1000

# ğŸ“° ê¸°ì‚¬ ë¡œë”©
def load_articles_from_directory(base_dir: str) -> List[Dict]:
    articles = []

    for newspaper in list_directories(base_dir):
        newspaper_dir = join_path(base_dir, newspaper)
        for filename in list_files(newspaper_dir, extension=".json"):
            json_path = join_path(newspaper_dir, filename)
            try:
                article = read_json_file(json_path)
                content = article.get("content", "")

                if not content:
                    logger.warning(f"âŒ Content ë¹„ì–´ìˆìŒ: {json_path}")
                    continue
                elif len(content) <= 100:
                    logger.warning(f"âŒ Content ê¸¸ì´ ë„ˆë¬´ ì§§ì€ ê¸°ì‚¬: {json_path}")
                    continue

                articles.append(article)
            except Exception as e:
                logger.error(f"âŒ {newspaper}/{filename} ì½ê¸° ì‹¤íŒ¨: {e}")
    
    logger.info(f"ì´ {len(articles)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ")
    return articles

# ğŸ§© ë°°ì¹˜ ë‚˜ëˆ„ê¸°
def batch_articles(articles: List[Dict], batch_size: int = MAX_BATCH_SIZE) -> List[List[Dict]]:
    return [articles[i:i + batch_size] for i in range(0, len(articles), batch_size)]

# ğŸš€ ë¹„ë™ê¸° API í˜¸ì¶œ
async def async_call_predict(session, batch, idx):
    try:
        async with session.post("http://34.64.121.216:8000/api/v1/predict", json=batch) as resp:
            logger.info(f"âœ… Batch {idx} ì‘ë‹µ ì½”ë“œ: {resp.status}")
    except Exception as e:
        logger.error(f"âŒ Batch {idx} ì‹¤íŒ¨: {e}")

async def async_predict_all_batches(batches):
    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as session:
        tasks = [async_call_predict(session, batch, idx+1) for idx, batch in enumerate(batches)]
        await asyncio.gather(*tasks)

# ğŸ¯ ìµœì¢… ì‹¤í–‰ í•¨ìˆ˜
def predict_economy_articles_task(parsed_dir: str):
    articles = load_articles_from_directory(parsed_dir)
    batches = batch_articles(articles)

    logger.info(f"ğŸš€ ì´ {len(batches)}ê°œ ë°°ì¹˜ async ìš”ì²­ ì‹œì‘")
    asyncio.run(async_predict_all_batches(batches))
    logger.info("âœ… ëª¨ë“  ê¸°ì‚¬ ì˜ˆì¸¡ ìš”ì²­ ì™„ë£Œ (ì„œë²„ì—ì„œ ìë™ ì²˜ë¦¬)")
